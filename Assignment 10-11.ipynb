{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "import random\n",
    "import copy\n",
    "import csv\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import the data file\n",
    "filename = 'spambase.data'\n",
    "filename2 = 'spambase.names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read the file into a python list\n",
    "with open(filename,'rU') as f:\n",
    "    reader = csv.reader(f)\n",
    "    #for line in reader:\n",
    "    dataset = [line for line in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read the fieldnames into a python list\n",
    "with open(filename2,'rU') as f:\n",
    "    reader = csv.reader(f,quoting=csv.QUOTE_NONE)\n",
    "    #for line in reader:\n",
    "        #print line\n",
    "    #test = [line[0][0] for line in reader if len(line) > 0 ]\n",
    "    #test = [ line[0] for line in reader if len(line) > 0 and '|' not in line[0] ]\n",
    "    fieldnames = [ line[0].split(\":\",1)[0] for line in reader if len(line) > 0 and '|' not in line[0] and line[0][0] != '1' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add field name spam_flag for the last field in the data file\n",
    "fieldnames.append('spam_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 58)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the length of fieldnames and the number of fields in the dataset\n",
    "len(fieldnames), len(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 500, 500, 3601, 4101)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#break the dataset into test set, dev set and train set\n",
    "#randomize the dataset\n",
    "random.shuffle(dataset)\n",
    "test_set, dev_set, train_set = dataset[0:500], dataset[500:1000], dataset[1000:]\n",
    "#combine dev and train for later reshuffle\n",
    "train_dev_set = train_set + dev_set\n",
    "#check set sizes\n",
    "len(dataset), len(test_set), len(dev_set), len(train_set), len(train_dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#start with the frequency of the word credit, since there are a lot of \n",
    "#credit card scams, maybe this signifies fraud\n",
    "def spam_features(line):\n",
    "    return {'credit': line[20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'credit': '2.38'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test function\n",
    "spam_features(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pair the features with the spam flag\n",
    "featureset_train = [(spam_features(line), line[-1]) for line in train_set]\n",
    "featureset_dev = [(spam_features(line), line[-1]) for line in dev_set]\n",
    "featureset_test = [(spam_features(line), line[-1]) for line in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(({'credit': '1.8'}, '1'), ({'credit': '0'}, '0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test what's in featuresets\n",
    "featureset_train[0],featureset_dev[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3601, 500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featureset_train), len(featureset_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(featureset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial classifier of the frequency of the word credit has an accuracy of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712\n"
     ]
    }
   ],
   "source": [
    "print nltk.classify.accuracy(classifier, featureset_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3601)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshuffle combined training set and dev set, and break it back into train and dev\n",
    "#test set remains separate\n",
    "random.shuffle(train_dev_set)\n",
    "dev_set, train_set = train_dev_set[0:500], train_dev_set[500:]\n",
    "len(dev_set), len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add the frequency of \"money\" to the featureset\n",
    "def spam_features2(name):\n",
    "    features = {}\n",
    "    features[\"credit\"] = line[20]\n",
    "    features[\"money\"] = line[24]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'credit': '0', 'money': '5.55'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test function\n",
    "spam_features2(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pair the features with the spam flag\n",
    "featureset_train2 = [(spam_features2(line), line[-1]) for line in train_set]\n",
    "featureset_dev2 = [(spam_features2(line), line[-1]) for line in dev_set]\n",
    "featureset_test2 = [(spam_features2(line), line[-1]) for line in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'credit': '0.66', 'money': '0.33'}, '1')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test featureset\n",
    "featureset_train2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create the classifier\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(featureset_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788\n"
     ]
    }
   ],
   "source": [
    "#print the accuracy of the classifier\n",
    "print nltk.classify.accuracy(classifier2, featureset_dev2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for this classifier is slightly higher than the initial classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3601)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshuffle combined training set and dev set, and break it back into train and dev\n",
    "#test set remains separate\n",
    "random.shuffle(train_dev_set)\n",
    "dev_set, train_set = train_dev_set[0:500], train_dev_set[500:]\n",
    "len(dev_set), len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add the frequency of \"free\" to the featureset\n",
    "def spam_features3(name):\n",
    "    features = {}\n",
    "    features[\"credit\"] = line[20]\n",
    "    features[\"money\"] = line[24]\n",
    "    features[\"free\"] = line[16]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'credit': '0', 'free': '0', 'money': '5.55'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test function\n",
    "spam_features3(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pair the features with the spam flag\n",
    "featureset_train3 = [(spam_features3(line), line[-1]) for line in train_set]\n",
    "featureset_dev3 = [(spam_features3(line), line[-1]) for line in dev_set]\n",
    "featureset_test3 = [(spam_features3(line), line[-1]) for line in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the classifier\n",
    "classifier3 = nltk.NaiveBayesClassifier.train(featureset_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756\n"
     ]
    }
   ],
   "source": [
    "#print the accuracy of the classifier\n",
    "print nltk.classify.accuracy(classifier3, featureset_dev3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3601)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshuffle combined training set and dev set, and break it back into train and dev\n",
    "#test set remains separate\n",
    "random.shuffle(train_dev_set)\n",
    "dev_set, train_set = train_dev_set[0:500], train_dev_set[500:]\n",
    "len(dev_set), len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add the frequency of \"receive\" and remove \"free\" to the featureset\n",
    "def spam_features4(name):\n",
    "    features = {}\n",
    "    features[\"credit\"] = line[20]\n",
    "    features[\"money\"] = line[24]\n",
    "    features[\"receive\"] = line[11]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pair the features with the spam flag\n",
    "featureset_train4 = [(spam_features4(line), line[-1]) for line in train_set]\n",
    "featureset_dev4 = [(spam_features4(line), line[-1]) for line in dev_set]\n",
    "featureset_test4 = [(spam_features4(line), line[-1]) for line in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "#create the classifier\n",
    "classifier4 = nltk.NaiveBayesClassifier.train(featureset_train4)\n",
    "\n",
    "#print the accuracy of the classifier\n",
    "print nltk.classify.accuracy(classifier4, featureset_dev4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No accuracy improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3601)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshuffle combined training set and dev set, and break it back into train and dev\n",
    "#test set remains separate\n",
    "random.shuffle(train_dev_set)\n",
    "dev_set, train_set = train_dev_set[0:500], train_dev_set[500:]\n",
    "len(dev_set), len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add the frequency of \"will\" but remove \"receive\" to the featureset\n",
    "def spam_features5(name):\n",
    "    features = {}\n",
    "    features[\"credit\"] = line[20]\n",
    "    features[\"money\"] = line[24]\n",
    "    features[\"will\"] = line[12]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pair the features with the spam flag\n",
    "featureset_train5 = [(spam_features5(line), line[-1]) for line in train_set]\n",
    "featureset_dev5 = [(spam_features5(line), line[-1]) for line in dev_set]\n",
    "featureset_test5 = [(spam_features5(line), line[-1]) for line in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802\n"
     ]
    }
   ],
   "source": [
    "#create the classifier\n",
    "classifier5 = nltk.NaiveBayesClassifier.train(featureset_train5)\n",
    "\n",
    "#print the accuracy of the classifier\n",
    "print nltk.classify.accuracy(classifier5, featureset_dev5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3601)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshuffle combined training set and dev set, and break it back into train and dev\n",
    "#test set remains separate\n",
    "random.shuffle(train_dev_set)\n",
    "dev_set, train_set = train_dev_set[0:500], train_dev_set[500:]\n",
    "len(dev_set), len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add the frequency of \";\" but remove \"will\" to the featureset\n",
    "def spam_features6(name):\n",
    "    features = {}\n",
    "    features[\"credit\"] = line[20]\n",
    "    features[\"money\"] = line[24]\n",
    "    features[\"will\"] = line[12]\n",
    "    features[\";\"] = line[49]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pair the features with the spam flag\n",
    "featureset_train6 = [(spam_features6(line), line[-1]) for line in train_set]\n",
    "featureset_dev6 = [(spam_features6(line), line[-1]) for line in dev_set]\n",
    "featureset_test6 = [(spam_features6(line), line[-1]) for line in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758\n"
     ]
    }
   ],
   "source": [
    "#create the classifier\n",
    "classifier6 = nltk.NaiveBayesClassifier.train(featureset_train6)\n",
    "\n",
    "#print the accuracy of the classifier\n",
    "print nltk.classify.accuracy(classifier6, featureset_dev6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not an improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774\n"
     ]
    }
   ],
   "source": [
    "#Test classifier 5 on the test_set.\n",
    "#print the accuracy of the classifier\n",
    "print nltk.classify.accuracy(classifier5, featureset_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.718, 0.774, 0.784, 0.762, 0.774, 0.764)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check all classifiers agains the test_set\n",
    "nltk.classify.accuracy(classifier, featureset_test), nltk.classify.accuracy(classifier2, featureset_test2), nltk.classify.accuracy(classifier3, featureset_test3), nltk.classify.accuracy(classifier4,featureset_test4),nltk.classify.accuracy(classifier5,featureset_test5), nltk.classify.accuracy(classifier6,featureset_test6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When testing the classifier on the test set classifier 3 has the highest accuracy, even though classifier 5 had the highest accuracy during the dev process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
